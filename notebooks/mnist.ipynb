{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "(784, 784)\n",
      "(784, 784)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normal_density_1 (NormalDens (None, 784)               2459408   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,467,258\n",
      "Trainable params: 622,506\n",
      "Non-trainable params: 1,844,752\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "class NormalDensity(layers.Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(NormalDensity, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name='w', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        self.alpha = self.add_weight(name='alpha', \n",
    "                              shape=(input_shape[1], self.output_dim),\n",
    "                              initializer='uniform',\n",
    "                              trainable=False)\n",
    "        self.y = self.add_weight(name='y', \n",
    "                              shape=(input_shape[1], self.output_dim),\n",
    "                              initializer='zeros',\n",
    "                              trainable=False)\n",
    "        self.hebb = self.add_weight(name='hebb', \n",
    "                              shape=(input_shape[1], self.output_dim),\n",
    "                              initializer='zeros',\n",
    "                              trainable=False)\n",
    "        self.eta = self.add_weight(name='eta', \n",
    "                                      shape=(input_shape[1], 1),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=False)\n",
    "        super(NormalDensity, self).build(input_shape)\n",
    "\n",
    "        \n",
    "        #yout = F.tanh( yin.mm(self.w + torch.mul(self.alpha, hebb)) + input )\n",
    "        #hebb = (1 - self.eta) * hebb + self.eta * torch.bmm(yin.unsqueeze(2), yout.unsqueeze(1))[0] # bmm here is used to implement an outer product between yin and yout, with the help of unsqueeze (i.e. added empty dimensions)\n",
    "        #return yout, hebb\n",
    "    def call(self, x):\n",
    "        yout = K.maximum(0.0, (K.dot(self.y, np.add(K.dot(self.alpha, K.transpose(self.hebb)), self.w))) + x)\n",
    "        print(yout.shape)\n",
    "        print(K.dot(self.y, yout).shape)\n",
    "        hebb = (1 - 0.01) * self.hebb + 0.01 * K.dot(self.y, yout)\n",
    "        self.y = yout\n",
    "        self.hebb = hebb\n",
    "        return yout\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(NormalDensity(784, input_shape=(784,)))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
